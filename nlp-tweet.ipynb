{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras-core --upgrade\n!pip install -q keras-nlp --upgrade\nimport os\nos.environ['KERAS_BACKEND'] = 'tensorflow'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport keras_core as keras\nimport keras_nlp\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"KerasNLP version:\", keras_nlp.__version__)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Disaster Tweets","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nprint('Training Set Shape = {}'.format(df_train.shape))\nprint('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\nprint('Test Set Shape = {}'.format(df_test.shape))\nprint('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore Dataset","metadata":{}},{"cell_type":"code","source":"df_train[\"length\"] = df_train[\"text\"].apply(lambda x : len(x))\ndf_test[\"length\"] = df_test[\"text\"].apply(lambda x : len(x))\nprint(\"Train Length Stat\")\nprint(df_train[\"length\"].describe())\nprint()\nprint(\"Test Length Stat\")\nprint(df_test[\"length\"].describe())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocess","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nNUM_TRAINING_EXAMPLES = df_train.shape[0]\nTRAIN_SPLIT = 0.8\nVAL_SPLIT = 0.2\nSTEPS_PER_EPOCH = int(NUM_TRAINING_EXAMPLES)*TRAIN_SPLIT // BATCH_SIZE\nEPOCHS = 2\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df_train[\"text\"]\ny = df_train[\"target\"]\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=VAL_SPLIT, random_state=42)\nX_test = df_test[\"text\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load a DistilBERT model from Keras NLP","metadata":{}},{"cell_type":"code","source":"preset= \"distil_bert_base_en_uncased\"\npreprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(preset,\n                                                                   sequence_length=160,\n                                                                   name=\"preprocessor_4_tweets\"\n                                                                  )\nclassifier = keras_nlp.models.DistilBertClassifier.from_preset(preset,\n                                                               preprocessor = preprocessor, \n                                                               num_classes=2)\nclassifier.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), #'binary_crossentropy',\n    optimizer=keras.optimizers.Adam(1e-5),\n    metrics= [\"accuracy\"]  \n)\nhistory = classifier.fit(x=X_train,\n                         y=y_train,\n                         batch_size=BATCH_SIZE,\n                         epochs=EPOCHS, \n                         validation_data=(X_val, y_val)\n                        )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def displayConfusionMatrix(y_true, y_pred, dataset):\n    disp = ConfusionMatrixDisplay.from_predictions(\n        y_true,\n        np.argmax(y_pred, axis=1),\n        display_labels=[\"Not Disaster\",\"Disaster\"],\n        cmap=plt.cm.Blues\n    )\n    tn, fp, fn, tp = confusion_matrix(y_true, np.argmax(y_pred, axis=1)).ravel()\n    f1_score = tp / (tp+((fn+fp)/2))\n    disp.ax_.set_title(\"Confusion Matrix on \" + dataset + \" Dataset -- F1 Score: \" + str(f1_score.round(2)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train = classifier.predict(X_train)\ndisplayConfusionMatrix(y_train, y_pred_train, \"Training\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_val = classifier.predict(X_val)\ndisplayConfusionMatrix(y_val, y_pred_val, \"Validation\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nsample_submission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[\"target\"] = np.argmax(classifier.predict(X_test), axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}